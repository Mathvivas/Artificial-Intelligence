{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMATmxUprhpQaYGKiQ1VD6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mathvivas/Artificial-Intelligence/blob/main/ConversationalBotWithSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIPOFHnFpa0C",
        "outputId": "f3677e42-deb5-41fa-98bc-06a2c1356494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/490.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m490.2/490.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --quiet -U langchain-huggingface langchain_core langchain_community langchain-tavily langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGING_FACE_API_KEY = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "5anj2GEIX5kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langgraph.graph import MessagesState\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage"
      ],
      "metadata": {
        "id": "RpDrsgQGa0US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=\"deepseek-ai/DeepSeek-V3.2\",\n",
        "    task=\"text-generation\",\n",
        "    temperature=0,\n",
        "    huggingfacehub_api_token=HUGGING_FACE_API_KEY\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=model, verbose=True)"
      ],
      "metadata": {
        "id": "JQ_ss0UUbH5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(MessagesState):\n",
        "    summary: str"
      ],
      "metadata": {
        "id": "gz8BSvttbMsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the logic of the node to call the model\n",
        "def call_model(state: State):\n",
        "    # Get the summary if it exists\n",
        "    summary = state.get('summary', '')\n",
        "\n",
        "    if summary:\n",
        "        # Add summary to system message\n",
        "        system_message = f'Summary of conversation earlier: {summary}'\n",
        "\n",
        "        # Append summary to any newer messages\n",
        "        messages = [SystemMessage(content=system_message)] + state['messages']\n",
        "    else:\n",
        "        messages = state['messages']\n",
        "\n",
        "    response = chat.invoke(messages)\n",
        "    return {'messages': response}"
      ],
      "metadata": {
        "id": "fUzJng0nbaZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the node to produce a summary\n",
        "def summarize_conversation(state: State):\n",
        "    # Get any existing summary\n",
        "    summary = state.get('summary', '')\n",
        "\n",
        "    # Create the summarization prompt\n",
        "    if summary:\n",
        "        summary_message = {\n",
        "            f'This is summary of the conversation to date: {summary}\\n\\n'\n",
        "            'Extend the summary by taking into account the new messages above.'\n",
        "        }\n",
        "    else:\n",
        "        summary_message = 'Create a summary of the conversation above.'\n",
        "\n",
        "    # Add prompt to the history\n",
        "    messages = state['messages'] + [HumanMessage(content=summary_message)]\n",
        "    response = chat.invoke(messages)\n",
        "\n",
        "    # Delete all but the 2 most recent messages\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state['messages'][:-2]]\n",
        "    return {'summary': response.content, 'messages': delete_messages}"
      ],
      "metadata": {
        "id": "EQo21qRPg4bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from typing_extensions import Literal"
      ],
      "metadata": {
        "id": "faoXs1tejmK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine whether to end or summarize the conversation\n",
        "def should_continue(state: State) -> Literal['summarize_conversation', END]:\n",
        "    '''Return the next node to execute.'''\n",
        "\n",
        "    messages = state['messages']\n",
        "\n",
        "    if len(messages) > 6:\n",
        "        return 'summarize_conversation'\n",
        "\n",
        "    return END"
      ],
      "metadata": {
        "id": "1arVl6cEj8_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START"
      ],
      "metadata": {
        "id": "etcqM6EeooIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "workflow.add_node('conversation', call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, 'conversation')\n",
        "workflow.add_conditional_edges('conversation', should_continue)\n",
        "workflow.add_edge('summarize_conversation', END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "sYGqSdbVoz5z",
        "outputId": "70180abe-e5a7-428e-ceff-513ec39ff6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a thread\n",
        "config = {'configurable': {'thread_id': '1'}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"Hi! I'm Matheus\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()\n",
        "\n",
        "input_message = HumanMessage(content=\"Can you point me to good sources to learn LangChain?\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shzb5wVasQn7",
        "outputId": "0da43e9c-474e-4d5c-b107-3eaf177ba102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Nice to meet you, Matheus! How can I help you today? üòä\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Certainly! Here are some excellent **sources for learning LangChain**, grouped by format and level:\n",
            "\n",
            "---\n",
            "\n",
            "## üß† **Official & Core Resources**  \n",
            "**Best starting point:**  \n",
            "1. **LangChain Documentation** ‚Äì Hugely detailed, with tutorials and API references  \n",
            "   ‚Üí [docs.langchain.com](https://docs.langchain.com)  \n",
            "2. **LangChain GitHub Repo** ‚Äì Examples, cookbooks, notebooks  \n",
            "   ‚Üí [github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)  \n",
            "\n",
            "---\n",
            "\n",
            "## üéì **Beginner-Friendly Tutorials & Courses**  \n",
            "- **LangChain Crash Course for Beginners** (free) ‚Äì YouTube playlist by **Greg Kamradt**  \n",
            "  ‚Üí Includes hands-on notebooks.  \n",
            "- **DeepLearning.AI Short Course**: *\"LangChain for LLM Application Development\"* (free)  \n",
            "  ‚Üí Taught by LangChain co-creator **Harrison Chase**.  \n",
            "- **Coursera Course**: *\"LangChain: Building LLM-Powered Applications\"*  \n",
            "- **YouTube** ‚Äì Search for **\"LangChain in 15 minutes\"** or **\"LangChain with OpenAI\"** (channels like *Nicholas Renotte*, *James Briggs*)  \n",
            "\n",
            "---\n",
            "\n",
            "## üìö **Books & Blogs**  \n",
            "- **\"LangChain in Action\"** by **William F. A. Marsh** (Manning Publications) ‚Äì step-by-step guide.  \n",
            "- **LangChain Blog** ‚Äì Announcements, case studies, guides  \n",
            "   ‚Üí [blog.langchain.dev](https://blog.langchain.dev)  \n",
            "- **Towards Data Science / Medium** ‚Äì Many practical tutorials by practitioners.  \n",
            "\n",
            "---\n",
            "\n",
            "## üõ†Ô∏è **Practice & Build**  \n",
            "- **LangChain Templates** ‚Äì Prebuilt chain templates for various use cases.  \n",
            "- **LangSmith** (by LangChain team) ‚Äì Debug, test, and monitor chains (free tier available).  \n",
            "- **Hugging Face Spaces** ‚Äì Deploy LangChain demos.  \n",
            "\n",
            "---\n",
            "\n",
            "## üìå **Key Topics to Explore**  \n",
            "Once you start, focus on:  \n",
            "1. **Prompts & LLMs** ‚Äì Prompt templates, few-shot learning.  \n",
            "2. **Chains** ‚Äì Sequential chains, transformation chains.  \n",
            "3. **Memory** ‚Äì Conversation memory, buffers.  \n",
            "4. **Agents & Tools** ‚Äì Using LLMs to choose actions/APIs.  \n",
            "5. **Retrieval-Augmented Generation (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"What tips can you give me to better my learning experience?\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rvmv65hAhGC",
        "outputId": "2346f822-3031-4b4b-d9ee-da44bafc852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Great question! Here are **actionable tips to optimize your LangChain learning journey**, based on learning efficiency and developer best practices:\n",
            "\n",
            "---\n",
            "\n",
            "## üß© **1. Start with the ‚ÄúWhy‚Äù Before the ‚ÄúHow‚Äù**\n",
            "- Understand **what problem LangChain solves** ‚Äî simplifying LLM integration, managing prompts, building agentic workflows, and connecting external data.\n",
            "- Ask yourself: *‚ÄúWhat kind of application do I want to build?‚Äù* ‚Äî chatbot, document analyzer, autonomous agent? That shapes your learning path.\n",
            "\n",
            "---\n",
            "\n",
            "## üß† **2. Learn By Building (Immediately)**\n",
            "Don‚Äôt just read ‚Äî **code from day one**:\n",
            "- **Follow a tutorial**, then modify it (change prompts, swap LLMs, add memory).\n",
            "- Start with a **simple Q&A bot**, then gradually add:\n",
            "  - Document retrieval (RAG)\n",
            "  - Tool/API integration\n",
            "  - Memory (conversation history)\n",
            "- Use **Google Colab** or **Jupyter notebooks** for quick experimentation.\n",
            "\n",
            "---\n",
            "\n",
            "## üìò **3. Grasp Core Concepts Step by Step**\n",
            "LangChain has many modules ‚Äî master them **in this order**:\n",
            "1. **Models (LLMs & ChatModels)** ‚Üí Learn to call OpenAI, Anthropic, or open-source models.\n",
            "2. **Prompts** ‚Üí Prompt templates, few-shot examples.\n",
            "3. **Chains** ‚Üí Simple chain ‚Üí sequential chain ‚Üí transformation chain.\n",
            "4. **Memory** ‚Üí ConversationBufferMemory, etc.\n",
            "5. **Indexes & Retrievers** ‚Üí For RAG (critical for real applications).\n",
            "6. **Agents & Tools** ‚Üí Let LLMs use calculators, search, APIs.\n",
            "\n",
            "---\n",
            "\n",
            "## üîÅ **4. Use the Official Docs Strategically**\n",
            "- Start with the **Getting Started** and **Tutorials** sections.\n",
            "- Use the **API reference** when you need specific class/method details.\n",
            "- **Search the docs** ‚Äî LangChain's documentation is extensive but well-organized.\n",
            "\n",
            "---\n",
            "\n",
            "## üß™ **5. Experiment & Break Things**\n",
            "- Try swapping one LLM for another (e.g., from GPT-4 to Llama 3 via Groq/Ollama).\n",
            "- **Break a working chain** intentionally to see error messages ‚Äî this builds debugging skills.\n",
            "- Play with **different retrieval methods** (vector stores: FAISS, Chroma, Pinecone).\n",
            "\n",
            "---\n",
            "\n",
            "## üõ†Ô∏è **6. Adopt Debugging Tools Early**\n",
            "- **LangSmith** (free tier)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"What are the differences between using RAG and tools?\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0-Ki5BtAica",
        "outputId": "0ab1bdef-2a96-462d-cc3e-8d1c2257ca9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Excellent question! **RAG** and **Tools** are two different approaches for enhancing LLMs with external information, each with distinct use cases and mechanisms:\n",
            "\n",
            "---\n",
            "\n",
            "## üîÑ **RAG (Retrieval-Augmented Generation)**\n",
            "### **What it is:**\n",
            "A technique that **retrieves relevant documents/chunks** from a knowledge base and injects them into the LLM's prompt to provide contextual information for generation.\n",
            "\n",
            "### **How it works:**\n",
            "1. **Indexing**: Documents are split into chunks ‚Üí embedded ‚Üí stored in a vector database.\n",
            "2. **Retrieval**: User query ‚Üí embedded ‚Üí similarity search ‚Üí top-k relevant chunks retrieved.\n",
            "3. **Augmentation**: Retrieved chunks + user query ‚Üí combined into a prompt ‚Üí sent to LLM.\n",
            "4. **Generation**: LLM generates answer based on retrieved context.\n",
            "\n",
            "### **Use Cases:**\n",
            "- **Question answering over documents** (PDFs, manuals, internal docs)\n",
            "- **Chat with your data** (company knowledge base, personal notes)\n",
            "- **Domain-specific assistance** (medical, legal, technical documentation)\n",
            "- **When you need factual accuracy** with source attribution\n",
            "\n",
            "### **Example:**\n",
            "```python\n",
            "# Simplified RAG flow\n",
            "query = \"What's LangChain's memory feature?\"\n",
            "retrieved_docs = vector_store.similarity_search(query)  # Get relevant chunks\n",
            "prompt = f\"Context: {retrieved_docs}\\nQuestion: {query}\"\n",
            "answer = llm.invoke(prompt)  # Generate with context\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## üõ†Ô∏è **Tools (Agent Tools)**\n",
            "### **What they are:**\n",
            "Functions or APIs that an **LLM agent can call** to perform specific tasks when needed, based on the user's request.\n",
            "\n",
            "### **How they work:**\n",
            "1. **Tool definition**: Each tool = a function with description (e.g., calculator, web search, API call).\n",
            "2. **Agent decision**: LLM decides *if* and *which* tool to use based on the query.\n",
            "3. **Execution**: Agent calls the tool with appropriate parameters.\n",
            "4. **Response**: Tool result is returned to LLM ‚Üí LLM synthesizes final answer.\n",
            "\n",
            "### **Use Cases:**\n",
            "- **Dynamic information needs** (current weather, stock prices, news)\n",
            "- **Computation/calculations** (math, currency conversion)\n",
            "- **Interactive actions** (send email, update database, web scraping)\n",
            "- **When you need real-time/live data** or to perform\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"Can I give you a name?\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYWLRjW-AkGn",
        "outputId": "56d5ed5c-f59a-4b11-f233-48471b36eed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "**Of course! üéâ** I'm your AI assistant, and you can absolutely give me any name you'd like ‚Äî it‚Äôs your choice. Names make interactions feel more personal and engaging.\n",
            "\n",
            "Do you already have a name in mind, or would you like some suggestions? üòä\n",
            "\n",
            "*(If you pick a name, I'll do my best to remember it for our future conversations!)*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"Do you remember my name or the last question I asked?\")\n",
        "output = graph.invoke({'messages': [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8HFY8spyRLv",
        "outputId": "6eabf27d-b831-40e8-d8eb-33b36bba4438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "**Yes!** Based on our conversation history in this chat:\n",
            "\n",
            "1. **Your name:** **Matheus** ‚Äî you introduced yourself earlier. üëã\n",
            "\n",
            "2. **Your last question:** You asked:  \n",
            "   *\"What are the differences between using RAG and tools?\"*  \n",
            "\n",
            "And I provided a detailed explanation comparing **RAG** (static document retrieval) vs. **Tools** (dynamic actions / APIs) in LLM applications. üß†\n",
            "\n",
            "---\n",
            "\n",
            "‚ö†Ô∏è **Note on memory:**  \n",
            "I remember the context **within this single chat session**, but I don‚Äôt retain memory across different chats or sessions‚Äîso in future conversations, you may need to reintroduce topics or provide context again.\n",
            "\n",
            "Would you like to keep going with more questions about RAG, tools, or anything else related to LangChain or LLMs?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_state(config).values.get('summary', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "7vjIaZNtwSrP",
        "outputId": "7e0195c6-87e2-4e56-e977-40751257c7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's a concise summary of our conversation:\\n\\n---\\n\\n### **üìå Conversation Summary**\\n\\n1. **Introduction**  \\n   - You introduced yourself as Matheus, and I greeted you as your AI assistant.\\n\\n2. **Learning LangChain**  \\n   - You asked for **sources to learn LangChain**. I provided a curated list including:\\n     - Official docs, GitHub repo\\n     - Tutorials (YouTube, courses by Harrison Chase, etc.)\\n     - Books and blogs\\n     - Tools for practice (LangSmith, templates)\\n     - Key topics to focus on (prompts, chains, memory, agents, RAG)\\n\\n3. **Learning Tips**  \\n   - You asked for **tips to improve your learning experience**. I suggested:\\n     - Start by understanding *why* LangChain exists\\n     - Learn by building immediately\\n     - Master concepts step-by-step (models ‚Üí prompts ‚Üí chains ‚Üí memory ‚Üí RAG ‚Üí agents)\\n     - Use docs strategically, experiment/debug early, join the community\\n\\n4. **RAG vs. Tools**  \\n   - You asked about the **difference between RAG and Tools**. I explained:\\n     - **RAG**: Retrieves static documents/knowledge ‚Üí augments prompts ‚Üí answers based on that context. Best for **document Q&A**.\\n     - **Tools**: Functions/APIs an agent can call dynamically ‚Üí gets live data or performs actions. Best for **real-time info or actions**.\\n\\n---\\n\\n### **üéØ Key Takeaway**\\nYou're exploring **LangChain** to build LLM-powered applications, starting with foundational learning resources, then optimizing your study approach, and clarifying core concepts like **RAG** (static knowledge retrieval) vs. **Tools** (dynamic action/API calls).\\n\\nReady to dive deeper into any of these topics? üòä\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}