{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdynamo"
      ],
      "metadata": {
        "id": "XH2gioaDCm2P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ChAI-o2McZbi"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights, vgg11, VGG11_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5qvEDsG1eAF",
        "outputId": "05c34c27-3b3b-4512-9dc0-dacfd71e8aab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm"
      ],
      "metadata": {
        "id": "6kHYjPKb1hY1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Label Map"
      ],
      "metadata": {
        "id": "W2lULp5Ce7iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    {'name': 'hello', 'id': 1},\n",
        "    {'name': 'yes', 'id': 2},\n",
        "    {'name': 'no', 'id': 3},\n",
        "    {'name': 'thanks', 'id': 4},\n",
        "    {'name': 'i love you', 'id': 5},\n",
        "]"
      ],
      "metadata": {
        "id": "ZgV6IlabeeFy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/annotations/\""
      ],
      "metadata": {
        "id": "5JUFI7svfUBo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/annotations/label_map.pbtxt', 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write(f'\\tname:\\'{label[\"name\"]}\\'\\n')\n",
        "        f.write(f'\\tid:{label[\"id\"]}\\n')\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "Y_8SEVEZeeC3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to Colab to get Images"
      ],
      "metadata": {
        "id": "ozpzfqhSgImy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eZyJ4a0gLgQ",
        "outputId": "c1a4167a-69ea-4fa2-89c6-9237c8a579f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/IA/signLanguageImages.zip\" -d \"/content/images\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak-ltHXgiWqs",
        "outputId": "6dfdf35d-5658-4b37-d200-f6ca698c5fa2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/IA/signLanguageImages.zip\n",
            "   creating: /content/images/test/\n",
            "  inflating: /content/images/test/hello.1636369e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/hello.1636369e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/hello.17697030-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/hello.17697030-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/iloveyou.643300ca-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/iloveyou.643300ca-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/iloveyou.65662e54-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/iloveyou.65662e54-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/no.54990236-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/no.54990236-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/no.58320d48-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/no.58320d48-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/thanks.223197d6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/thanks.223197d6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/thanks.29631fe8-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/thanks.29631fe8-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/yes.356557d4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/yes.356557d4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/yes.36989634-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/yes.36989634-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "   creating: /content/images/train/\n",
            "  inflating: /content/images/train/hello.07b8a200-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.07b8a200-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.08ff8ab6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.08ff8ab6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0a32d26c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0a32d26c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0b6614a0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0b6614a0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0c9c8872-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0c9c8872-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0dd0807c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0dd0807c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0f03c15c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0f03c15c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.10371a4c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.10371a4c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.116a0c08-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.116a0c08-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.129d16ba-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.129d16ba-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.13d00236-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.13d00236-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.1502fabe-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.1502fabe-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.189cc68c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.189cc68c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.5e308968-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.5e308968-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.5f6684cc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.5f6684cc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6099b01c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6099b01c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.61cccb4a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.61cccb4a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.62ffc0b2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.62ffc0b2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6699e1e4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6699e1e4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.67cd878c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.67cd878c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6900b17e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6900b17e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6a33b37a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6a33b37a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6b6713d6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6b6713d6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6c9daee0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6c9daee0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6dd0a9a2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6dd0a9a2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6f03c6b0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6f03c6b0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4895e2ce-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4895e2ce-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.49c94ac8-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.49c94ac8-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4afc7ff0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4afc7ff0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4c2f8264-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4c2f8264-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4d628c9e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4d628c9e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4e956988-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4e956988-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4fc86d5a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4fc86d5a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.50fb6e84-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.50fb6e84-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.522efc4e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.522efc4e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.5365fe1e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.5365fe1e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.55cbcd50-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.55cbcd50-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.56fec54c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.56fec54c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.5968d066-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.5968d066-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1d61b312-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1d61b312-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1e9781bc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1e9781bc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1fcaa99c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1fcaa99c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.20fde9f0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.20fde9f0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.23646c32-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.23646c32-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.24970d26-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.24970d26-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.25ca3bdc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.25ca3bdc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.26fcf5e4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.26fcf5e4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.282ff4ca-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.282ff4ca-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2a96002e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2a96002e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2bc8f866-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2bc8f866-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2cfc1e34-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2cfc1e34-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2e300c3e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2e300c3e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.32fbfab6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.32fbfab6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.34320a9c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.34320a9c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.37cbab04-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.37cbab04-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.38feb796-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.38feb796-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3a31b014-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3a31b014-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3b649e92-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3b649e92-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3c979b34-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3c979b34-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3dca9d08-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3dca9d08-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3efd905e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3efd905e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.40309aa2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.40309aa2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.4163b12a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.4163b12a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.4296bbb4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.4296bbb4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.43c9debc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.43c9debc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SignDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None,\n",
        "                 device='cpu'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "\n",
        "        self.image_label_pairs = []\n",
        "        split_dir = os.path.join(root_dir, split)\n",
        "\n",
        "        for filename in os.listdir(split_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img_path = os.path.join(split_dir, filename)\n",
        "                label_filename = os.path.splitext(filename)[0] + '.xml'\n",
        "                label_path = os.path.join(split_dir, label_filename)\n",
        "                if os.path.exists(label_path):\n",
        "                    self.image_label_pairs.append((img_path, label_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_label_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label_path = self.image_label_pairs[idx]\n",
        "\n",
        "        # Load Image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Load XML file and extract label information\n",
        "        tree = ET.parse(label_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Extract label information\n",
        "        object_elem = root.find('object')\n",
        "        class_name = object_elem.find('name').text\n",
        "        bbox_elem = object_elem.find('bndbox')\n",
        "        xmin = int(bbox_elem.find('xmin').text)\n",
        "        ymin = int(bbox_elem.find('ymin').text)\n",
        "        xmax = int(bbox_elem.find('xmax').text)\n",
        "        ymax = int(bbox_elem.find('ymax').text)\n",
        "\n",
        "        # Create label information\n",
        "        label_info = {\n",
        "            'class_name': class_name,\n",
        "            'bbox': [xmin, ymin, xmax, ymax]\n",
        "        }\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return {'image': img, 'label': label_info}"
      ],
      "metadata": {
        "id": "ZcXuVEUsdJEO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "nPyryh28eU5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "eq8CpTGCdo6V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "cedreQCMKvvj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Dataset"
      ],
      "metadata": {
        "id": "__EUi9pseZul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SignDataset(root_dir='/content/images', split='train',\n",
        "                            transform=transform, device=device)\n",
        "test_dataset = SignDataset(root_dir='/content/images', split='test',\n",
        "                           transform=transform, device=device)"
      ],
      "metadata": {
        "id": "fVkzErFHd1RW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA_nmpUnMnZ6",
        "outputId": "d3e0f682-cd79-4d20-b436-32fd28983315"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[0.2863, 0.2549, 0.2510,  ..., 0.2392, 0.2431, 0.2471],\n",
              "          [0.2863, 0.2549, 0.2510,  ..., 0.2314, 0.2353, 0.2353],\n",
              "          [0.2667, 0.2431, 0.2549,  ..., 0.2196, 0.2235, 0.2196],\n",
              "          ...,\n",
              "          [0.1059, 0.1137, 0.1059,  ..., 0.1098, 0.1176, 0.1137],\n",
              "          [0.1176, 0.1176, 0.1098,  ..., 0.1098, 0.1098, 0.1098],\n",
              "          [0.1020, 0.1137, 0.1216,  ..., 0.0980, 0.1176, 0.1176]],\n",
              " \n",
              "         [[0.3333, 0.3176, 0.3137,  ..., 0.2118, 0.2118, 0.2078],\n",
              "          [0.3412, 0.3176, 0.3137,  ..., 0.2196, 0.2275, 0.2196],\n",
              "          [0.3451, 0.3255, 0.3255,  ..., 0.2196, 0.2353, 0.2275],\n",
              "          ...,\n",
              "          [0.1059, 0.1137, 0.1059,  ..., 0.0941, 0.0941, 0.0980],\n",
              "          [0.1255, 0.1255, 0.1176,  ..., 0.0941, 0.0863, 0.0863],\n",
              "          [0.0980, 0.1098, 0.1137,  ..., 0.0902, 0.0902, 0.0941]],\n",
              " \n",
              "         [[0.3451, 0.3490, 0.3647,  ..., 0.2157, 0.2235, 0.2275],\n",
              "          [0.3490, 0.3490, 0.3608,  ..., 0.2235, 0.2275, 0.2235],\n",
              "          [0.3412, 0.3333, 0.3569,  ..., 0.2275, 0.2275, 0.2157],\n",
              "          ...,\n",
              "          [0.1216, 0.1490, 0.1647,  ..., 0.1804, 0.1608, 0.1569],\n",
              "          [0.1333, 0.1569, 0.1725,  ..., 0.1569, 0.1412, 0.1412],\n",
              "          [0.1333, 0.1569, 0.1843,  ..., 0.1255, 0.1294, 0.1412]]]),\n",
              " 'label': {'class_name': 'no', 'bbox': [343, 266, 569, 433]}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Pretrained Model"
      ],
      "metadata": {
        "id": "rxNrHi8Sv5rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "def get_state_dict(self, *args, **kwargs):\n",
        "    kwargs.pop(\"check_hash\")\n",
        "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "model = efficientnet_b0(weights=\"DEFAULT\")"
      ],
      "metadata": {
        "id": "VOUg0xiLkHCW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freezing Model's Weights"
      ],
      "metadata": {
        "id": "u37_aQktyx4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "metadata": {
        "id": "0fYEaDuiyxb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modifying the Final Fully Connected Layer"
      ],
      "metadata": {
        "id": "6-UFlb1_wD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBXXIU231qlQ",
        "outputId": "897e5962-22fa-44a2-99b7-926a53a60959"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 6\n",
        "model.classifier = nn.Linear(model.classifier[-1].in_features, NUM_CLASSES)\n",
        "model.classifier"
      ],
      "metadata": {
        "id": "bZGVC-gVkI22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09dbde8-731c-4eb2-dbee-0d2ffb0f1ff9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1280, out_features=6, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data = torch.randn(3, 224, 224).to(device)\n",
        "# model = model.to(device)\n",
        "# summary(model, input_data.shape[1:])"
      ],
      "metadata": {
        "id": "8_9NI5vVy9Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "HA8Stuqqxiwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "Ba6ZVYnBvLsM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "-yCWak0QzoTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "cC1z0Si8vLpQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_index_mapping = {label['name']: label['id'] for label in labels}\n",
        "class_index_mapping"
      ],
      "metadata": {
        "id": "txiAe1Mt2WZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd63fd3-17df-4f5c-c8d9-c091b52cd8a5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hello': 1, 'yes': 2, 'no': 3, 'thanks': 4, 'i love you': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "aIju5rp8A_WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed3d0f7-fa30-4e40-8cb0-ae0a4a0a6bcf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[0.3020, 0.2824, 0.2902,  ..., 0.2353, 0.2471, 0.2510],\n",
              "          [0.3098, 0.2941, 0.2980,  ..., 0.2235, 0.2353, 0.2431],\n",
              "          [0.3137, 0.3059, 0.3098,  ..., 0.2275, 0.2431, 0.2510],\n",
              "          ...,\n",
              "          [0.7647, 0.7882, 0.8196,  ..., 0.1647, 0.1686, 0.1686],\n",
              "          [0.7725, 0.7961, 0.8196,  ..., 0.1608, 0.1765, 0.1804],\n",
              "          [0.7647, 0.7882, 0.8118,  ..., 0.1529, 0.1725, 0.1765]],\n",
              " \n",
              "         [[0.4039, 0.3647, 0.3373,  ..., 0.2510, 0.2588, 0.2549],\n",
              "          [0.3922, 0.3608, 0.3373,  ..., 0.2471, 0.2510, 0.2510],\n",
              "          [0.3804, 0.3529, 0.3333,  ..., 0.2471, 0.2510, 0.2471],\n",
              "          ...,\n",
              "          [0.7647, 0.7922, 0.8275,  ..., 0.1647, 0.1608, 0.1608],\n",
              "          [0.7843, 0.8039, 0.8392,  ..., 0.1608, 0.1608, 0.1569],\n",
              "          [0.7961, 0.8196, 0.8471,  ..., 0.1529, 0.1490, 0.1373]],\n",
              " \n",
              "         [[0.4235, 0.3961, 0.3843,  ..., 0.2745, 0.2745, 0.2706],\n",
              "          [0.4392, 0.4157, 0.3961,  ..., 0.2784, 0.2784, 0.2745],\n",
              "          [0.4235, 0.4078, 0.3922,  ..., 0.2745, 0.2745, 0.2706],\n",
              "          ...,\n",
              "          [0.7608, 0.7922, 0.8314,  ..., 0.2275, 0.2196, 0.2157],\n",
              "          [0.7843, 0.8157, 0.8471,  ..., 0.1843, 0.1961, 0.2078],\n",
              "          [0.8039, 0.8275, 0.8549,  ..., 0.1529, 0.1922, 0.2235]]]),\n",
              " 'label': {'class_name': 'hello', 'bbox': [52, 80, 267, 338]}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_torch = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device_torch)\n",
        "next(model.parameters()).is_cuda"
      ],
      "metadata": {
        "id": "CH9e6HzPNaaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80ba57e-2779-4dc5-e5d3-ad143a53737b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    for idx in range(len(train_dataset)):\n",
        "        sample = train_dataset[idx]\n",
        "        x, y = sample['image'], sample['label']\n",
        "        x = x.to(device)\n",
        "        x = x.unsqueeze(0)\n",
        "        # x = x.view(-1, 224, 224, 3)\n",
        "        # x = x.permute(0, 3, 1, 2)\n",
        "        # print(x.shape)\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(x)\n",
        "        y_pred = y_pred.to(device)\n",
        "        label = torch.tensor(class_index_mapping[y['class_name']], device=device)\n",
        "\n",
        "        loss = loss_fn(y_pred, label.unsqueeze(0))\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss / len(train_dataset)}')"
      ],
      "metadata": {
        "id": "T6xgELwOvLla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6e6356-0aee-49f4-f743-a65c24422c26"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.7683257964941173\n",
            "Epoch [2/10], Loss: 1.604168334374061\n",
            "Epoch [3/10], Loss: 1.4922878485459548\n",
            "Epoch [4/10], Loss: 1.3488183470872732\n",
            "Epoch [5/10], Loss: 1.1874702765391423\n",
            "Epoch [6/10], Loss: 1.001362753372926\n",
            "Epoch [7/10], Loss: 0.8920926997294792\n",
            "Epoch [8/10], Loss: 0.6930442250691927\n",
            "Epoch [9/10], Loss: 0.5241159890706723\n",
            "Epoch [10/10], Loss: 0.4001792924908491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model"
      ],
      "metadata": {
        "id": "rYHWYz0wCCP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss_test = 0.0\n",
        "        for idx in range(len(test_dataset)):\n",
        "            sample = test_dataset[idx]\n",
        "            x, y = sample['image'], sample['label']\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred = model(x.unsqueeze(0))\n",
        "            # print(y_pred)\n",
        "            #tensor([[-2.3828,  0.5092,  1.6678,  0.0214, -0.8732,  0.6362]],\n",
        "            y_pred = y_pred.to(device)\n",
        "            label = torch.tensor(class_index_mapping[y['class_name']])\\\n",
        "                    .to(device)\n",
        "            loss = loss_fn(y_pred, label.unsqueeze(0))\n",
        "\n",
        "            running_loss_test += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss_test / len(test_dataset)}')"
      ],
      "metadata": {
        "id": "lGnqCKjGvLiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269b33b1-9da5-434c-b5bd-017c082363b6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8505194678902626\n",
            "Epoch [2/10], Loss: 0.8505194678902626\n",
            "Epoch [3/10], Loss: 0.8505194678902626\n",
            "Epoch [4/10], Loss: 0.8505194678902626\n",
            "Epoch [5/10], Loss: 0.8505194678902626\n",
            "Epoch [6/10], Loss: 0.8505194678902626\n",
            "Epoch [7/10], Loss: 0.8505194678902626\n",
            "Epoch [8/10], Loss: 0.8505194678902626\n",
            "Epoch [9/10], Loss: 0.8505194678902626\n",
            "Epoch [10/10], Loss: 0.8505194678902626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the Weights of the Model"
      ],
      "metadata": {
        "id": "WZisOlyLVlWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = model.state_dict()\n",
        "state['classifier.1.weight'] = state['classifier.weight']\n",
        "del state['classifier.weight']\n",
        "state['classifier.1.bias'] = state['classifier.bias']\n",
        "del state['classifier.bias']"
      ],
      "metadata": {
        "id": "kVtISBYcnH0P"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in state.items():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXw_SEk3iSg1",
        "outputId": "b05ba2d4-909e-49c1-d253-da12a55e13c3"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.0.0.weight\n",
            "features.0.1.weight\n",
            "features.0.1.bias\n",
            "features.0.1.running_mean\n",
            "features.0.1.running_var\n",
            "features.0.1.num_batches_tracked\n",
            "features.1.0.block.0.0.weight\n",
            "features.1.0.block.0.1.weight\n",
            "features.1.0.block.0.1.bias\n",
            "features.1.0.block.0.1.running_mean\n",
            "features.1.0.block.0.1.running_var\n",
            "features.1.0.block.0.1.num_batches_tracked\n",
            "features.1.0.block.1.fc1.weight\n",
            "features.1.0.block.1.fc1.bias\n",
            "features.1.0.block.1.fc2.weight\n",
            "features.1.0.block.1.fc2.bias\n",
            "features.1.0.block.2.0.weight\n",
            "features.1.0.block.2.1.weight\n",
            "features.1.0.block.2.1.bias\n",
            "features.1.0.block.2.1.running_mean\n",
            "features.1.0.block.2.1.running_var\n",
            "features.1.0.block.2.1.num_batches_tracked\n",
            "features.2.0.block.0.0.weight\n",
            "features.2.0.block.0.1.weight\n",
            "features.2.0.block.0.1.bias\n",
            "features.2.0.block.0.1.running_mean\n",
            "features.2.0.block.0.1.running_var\n",
            "features.2.0.block.0.1.num_batches_tracked\n",
            "features.2.0.block.1.0.weight\n",
            "features.2.0.block.1.1.weight\n",
            "features.2.0.block.1.1.bias\n",
            "features.2.0.block.1.1.running_mean\n",
            "features.2.0.block.1.1.running_var\n",
            "features.2.0.block.1.1.num_batches_tracked\n",
            "features.2.0.block.2.fc1.weight\n",
            "features.2.0.block.2.fc1.bias\n",
            "features.2.0.block.2.fc2.weight\n",
            "features.2.0.block.2.fc2.bias\n",
            "features.2.0.block.3.0.weight\n",
            "features.2.0.block.3.1.weight\n",
            "features.2.0.block.3.1.bias\n",
            "features.2.0.block.3.1.running_mean\n",
            "features.2.0.block.3.1.running_var\n",
            "features.2.0.block.3.1.num_batches_tracked\n",
            "features.2.1.block.0.0.weight\n",
            "features.2.1.block.0.1.weight\n",
            "features.2.1.block.0.1.bias\n",
            "features.2.1.block.0.1.running_mean\n",
            "features.2.1.block.0.1.running_var\n",
            "features.2.1.block.0.1.num_batches_tracked\n",
            "features.2.1.block.1.0.weight\n",
            "features.2.1.block.1.1.weight\n",
            "features.2.1.block.1.1.bias\n",
            "features.2.1.block.1.1.running_mean\n",
            "features.2.1.block.1.1.running_var\n",
            "features.2.1.block.1.1.num_batches_tracked\n",
            "features.2.1.block.2.fc1.weight\n",
            "features.2.1.block.2.fc1.bias\n",
            "features.2.1.block.2.fc2.weight\n",
            "features.2.1.block.2.fc2.bias\n",
            "features.2.1.block.3.0.weight\n",
            "features.2.1.block.3.1.weight\n",
            "features.2.1.block.3.1.bias\n",
            "features.2.1.block.3.1.running_mean\n",
            "features.2.1.block.3.1.running_var\n",
            "features.2.1.block.3.1.num_batches_tracked\n",
            "features.3.0.block.0.0.weight\n",
            "features.3.0.block.0.1.weight\n",
            "features.3.0.block.0.1.bias\n",
            "features.3.0.block.0.1.running_mean\n",
            "features.3.0.block.0.1.running_var\n",
            "features.3.0.block.0.1.num_batches_tracked\n",
            "features.3.0.block.1.0.weight\n",
            "features.3.0.block.1.1.weight\n",
            "features.3.0.block.1.1.bias\n",
            "features.3.0.block.1.1.running_mean\n",
            "features.3.0.block.1.1.running_var\n",
            "features.3.0.block.1.1.num_batches_tracked\n",
            "features.3.0.block.2.fc1.weight\n",
            "features.3.0.block.2.fc1.bias\n",
            "features.3.0.block.2.fc2.weight\n",
            "features.3.0.block.2.fc2.bias\n",
            "features.3.0.block.3.0.weight\n",
            "features.3.0.block.3.1.weight\n",
            "features.3.0.block.3.1.bias\n",
            "features.3.0.block.3.1.running_mean\n",
            "features.3.0.block.3.1.running_var\n",
            "features.3.0.block.3.1.num_batches_tracked\n",
            "features.3.1.block.0.0.weight\n",
            "features.3.1.block.0.1.weight\n",
            "features.3.1.block.0.1.bias\n",
            "features.3.1.block.0.1.running_mean\n",
            "features.3.1.block.0.1.running_var\n",
            "features.3.1.block.0.1.num_batches_tracked\n",
            "features.3.1.block.1.0.weight\n",
            "features.3.1.block.1.1.weight\n",
            "features.3.1.block.1.1.bias\n",
            "features.3.1.block.1.1.running_mean\n",
            "features.3.1.block.1.1.running_var\n",
            "features.3.1.block.1.1.num_batches_tracked\n",
            "features.3.1.block.2.fc1.weight\n",
            "features.3.1.block.2.fc1.bias\n",
            "features.3.1.block.2.fc2.weight\n",
            "features.3.1.block.2.fc2.bias\n",
            "features.3.1.block.3.0.weight\n",
            "features.3.1.block.3.1.weight\n",
            "features.3.1.block.3.1.bias\n",
            "features.3.1.block.3.1.running_mean\n",
            "features.3.1.block.3.1.running_var\n",
            "features.3.1.block.3.1.num_batches_tracked\n",
            "features.4.0.block.0.0.weight\n",
            "features.4.0.block.0.1.weight\n",
            "features.4.0.block.0.1.bias\n",
            "features.4.0.block.0.1.running_mean\n",
            "features.4.0.block.0.1.running_var\n",
            "features.4.0.block.0.1.num_batches_tracked\n",
            "features.4.0.block.1.0.weight\n",
            "features.4.0.block.1.1.weight\n",
            "features.4.0.block.1.1.bias\n",
            "features.4.0.block.1.1.running_mean\n",
            "features.4.0.block.1.1.running_var\n",
            "features.4.0.block.1.1.num_batches_tracked\n",
            "features.4.0.block.2.fc1.weight\n",
            "features.4.0.block.2.fc1.bias\n",
            "features.4.0.block.2.fc2.weight\n",
            "features.4.0.block.2.fc2.bias\n",
            "features.4.0.block.3.0.weight\n",
            "features.4.0.block.3.1.weight\n",
            "features.4.0.block.3.1.bias\n",
            "features.4.0.block.3.1.running_mean\n",
            "features.4.0.block.3.1.running_var\n",
            "features.4.0.block.3.1.num_batches_tracked\n",
            "features.4.1.block.0.0.weight\n",
            "features.4.1.block.0.1.weight\n",
            "features.4.1.block.0.1.bias\n",
            "features.4.1.block.0.1.running_mean\n",
            "features.4.1.block.0.1.running_var\n",
            "features.4.1.block.0.1.num_batches_tracked\n",
            "features.4.1.block.1.0.weight\n",
            "features.4.1.block.1.1.weight\n",
            "features.4.1.block.1.1.bias\n",
            "features.4.1.block.1.1.running_mean\n",
            "features.4.1.block.1.1.running_var\n",
            "features.4.1.block.1.1.num_batches_tracked\n",
            "features.4.1.block.2.fc1.weight\n",
            "features.4.1.block.2.fc1.bias\n",
            "features.4.1.block.2.fc2.weight\n",
            "features.4.1.block.2.fc2.bias\n",
            "features.4.1.block.3.0.weight\n",
            "features.4.1.block.3.1.weight\n",
            "features.4.1.block.3.1.bias\n",
            "features.4.1.block.3.1.running_mean\n",
            "features.4.1.block.3.1.running_var\n",
            "features.4.1.block.3.1.num_batches_tracked\n",
            "features.4.2.block.0.0.weight\n",
            "features.4.2.block.0.1.weight\n",
            "features.4.2.block.0.1.bias\n",
            "features.4.2.block.0.1.running_mean\n",
            "features.4.2.block.0.1.running_var\n",
            "features.4.2.block.0.1.num_batches_tracked\n",
            "features.4.2.block.1.0.weight\n",
            "features.4.2.block.1.1.weight\n",
            "features.4.2.block.1.1.bias\n",
            "features.4.2.block.1.1.running_mean\n",
            "features.4.2.block.1.1.running_var\n",
            "features.4.2.block.1.1.num_batches_tracked\n",
            "features.4.2.block.2.fc1.weight\n",
            "features.4.2.block.2.fc1.bias\n",
            "features.4.2.block.2.fc2.weight\n",
            "features.4.2.block.2.fc2.bias\n",
            "features.4.2.block.3.0.weight\n",
            "features.4.2.block.3.1.weight\n",
            "features.4.2.block.3.1.bias\n",
            "features.4.2.block.3.1.running_mean\n",
            "features.4.2.block.3.1.running_var\n",
            "features.4.2.block.3.1.num_batches_tracked\n",
            "features.5.0.block.0.0.weight\n",
            "features.5.0.block.0.1.weight\n",
            "features.5.0.block.0.1.bias\n",
            "features.5.0.block.0.1.running_mean\n",
            "features.5.0.block.0.1.running_var\n",
            "features.5.0.block.0.1.num_batches_tracked\n",
            "features.5.0.block.1.0.weight\n",
            "features.5.0.block.1.1.weight\n",
            "features.5.0.block.1.1.bias\n",
            "features.5.0.block.1.1.running_mean\n",
            "features.5.0.block.1.1.running_var\n",
            "features.5.0.block.1.1.num_batches_tracked\n",
            "features.5.0.block.2.fc1.weight\n",
            "features.5.0.block.2.fc1.bias\n",
            "features.5.0.block.2.fc2.weight\n",
            "features.5.0.block.2.fc2.bias\n",
            "features.5.0.block.3.0.weight\n",
            "features.5.0.block.3.1.weight\n",
            "features.5.0.block.3.1.bias\n",
            "features.5.0.block.3.1.running_mean\n",
            "features.5.0.block.3.1.running_var\n",
            "features.5.0.block.3.1.num_batches_tracked\n",
            "features.5.1.block.0.0.weight\n",
            "features.5.1.block.0.1.weight\n",
            "features.5.1.block.0.1.bias\n",
            "features.5.1.block.0.1.running_mean\n",
            "features.5.1.block.0.1.running_var\n",
            "features.5.1.block.0.1.num_batches_tracked\n",
            "features.5.1.block.1.0.weight\n",
            "features.5.1.block.1.1.weight\n",
            "features.5.1.block.1.1.bias\n",
            "features.5.1.block.1.1.running_mean\n",
            "features.5.1.block.1.1.running_var\n",
            "features.5.1.block.1.1.num_batches_tracked\n",
            "features.5.1.block.2.fc1.weight\n",
            "features.5.1.block.2.fc1.bias\n",
            "features.5.1.block.2.fc2.weight\n",
            "features.5.1.block.2.fc2.bias\n",
            "features.5.1.block.3.0.weight\n",
            "features.5.1.block.3.1.weight\n",
            "features.5.1.block.3.1.bias\n",
            "features.5.1.block.3.1.running_mean\n",
            "features.5.1.block.3.1.running_var\n",
            "features.5.1.block.3.1.num_batches_tracked\n",
            "features.5.2.block.0.0.weight\n",
            "features.5.2.block.0.1.weight\n",
            "features.5.2.block.0.1.bias\n",
            "features.5.2.block.0.1.running_mean\n",
            "features.5.2.block.0.1.running_var\n",
            "features.5.2.block.0.1.num_batches_tracked\n",
            "features.5.2.block.1.0.weight\n",
            "features.5.2.block.1.1.weight\n",
            "features.5.2.block.1.1.bias\n",
            "features.5.2.block.1.1.running_mean\n",
            "features.5.2.block.1.1.running_var\n",
            "features.5.2.block.1.1.num_batches_tracked\n",
            "features.5.2.block.2.fc1.weight\n",
            "features.5.2.block.2.fc1.bias\n",
            "features.5.2.block.2.fc2.weight\n",
            "features.5.2.block.2.fc2.bias\n",
            "features.5.2.block.3.0.weight\n",
            "features.5.2.block.3.1.weight\n",
            "features.5.2.block.3.1.bias\n",
            "features.5.2.block.3.1.running_mean\n",
            "features.5.2.block.3.1.running_var\n",
            "features.5.2.block.3.1.num_batches_tracked\n",
            "features.6.0.block.0.0.weight\n",
            "features.6.0.block.0.1.weight\n",
            "features.6.0.block.0.1.bias\n",
            "features.6.0.block.0.1.running_mean\n",
            "features.6.0.block.0.1.running_var\n",
            "features.6.0.block.0.1.num_batches_tracked\n",
            "features.6.0.block.1.0.weight\n",
            "features.6.0.block.1.1.weight\n",
            "features.6.0.block.1.1.bias\n",
            "features.6.0.block.1.1.running_mean\n",
            "features.6.0.block.1.1.running_var\n",
            "features.6.0.block.1.1.num_batches_tracked\n",
            "features.6.0.block.2.fc1.weight\n",
            "features.6.0.block.2.fc1.bias\n",
            "features.6.0.block.2.fc2.weight\n",
            "features.6.0.block.2.fc2.bias\n",
            "features.6.0.block.3.0.weight\n",
            "features.6.0.block.3.1.weight\n",
            "features.6.0.block.3.1.bias\n",
            "features.6.0.block.3.1.running_mean\n",
            "features.6.0.block.3.1.running_var\n",
            "features.6.0.block.3.1.num_batches_tracked\n",
            "features.6.1.block.0.0.weight\n",
            "features.6.1.block.0.1.weight\n",
            "features.6.1.block.0.1.bias\n",
            "features.6.1.block.0.1.running_mean\n",
            "features.6.1.block.0.1.running_var\n",
            "features.6.1.block.0.1.num_batches_tracked\n",
            "features.6.1.block.1.0.weight\n",
            "features.6.1.block.1.1.weight\n",
            "features.6.1.block.1.1.bias\n",
            "features.6.1.block.1.1.running_mean\n",
            "features.6.1.block.1.1.running_var\n",
            "features.6.1.block.1.1.num_batches_tracked\n",
            "features.6.1.block.2.fc1.weight\n",
            "features.6.1.block.2.fc1.bias\n",
            "features.6.1.block.2.fc2.weight\n",
            "features.6.1.block.2.fc2.bias\n",
            "features.6.1.block.3.0.weight\n",
            "features.6.1.block.3.1.weight\n",
            "features.6.1.block.3.1.bias\n",
            "features.6.1.block.3.1.running_mean\n",
            "features.6.1.block.3.1.running_var\n",
            "features.6.1.block.3.1.num_batches_tracked\n",
            "features.6.2.block.0.0.weight\n",
            "features.6.2.block.0.1.weight\n",
            "features.6.2.block.0.1.bias\n",
            "features.6.2.block.0.1.running_mean\n",
            "features.6.2.block.0.1.running_var\n",
            "features.6.2.block.0.1.num_batches_tracked\n",
            "features.6.2.block.1.0.weight\n",
            "features.6.2.block.1.1.weight\n",
            "features.6.2.block.1.1.bias\n",
            "features.6.2.block.1.1.running_mean\n",
            "features.6.2.block.1.1.running_var\n",
            "features.6.2.block.1.1.num_batches_tracked\n",
            "features.6.2.block.2.fc1.weight\n",
            "features.6.2.block.2.fc1.bias\n",
            "features.6.2.block.2.fc2.weight\n",
            "features.6.2.block.2.fc2.bias\n",
            "features.6.2.block.3.0.weight\n",
            "features.6.2.block.3.1.weight\n",
            "features.6.2.block.3.1.bias\n",
            "features.6.2.block.3.1.running_mean\n",
            "features.6.2.block.3.1.running_var\n",
            "features.6.2.block.3.1.num_batches_tracked\n",
            "features.6.3.block.0.0.weight\n",
            "features.6.3.block.0.1.weight\n",
            "features.6.3.block.0.1.bias\n",
            "features.6.3.block.0.1.running_mean\n",
            "features.6.3.block.0.1.running_var\n",
            "features.6.3.block.0.1.num_batches_tracked\n",
            "features.6.3.block.1.0.weight\n",
            "features.6.3.block.1.1.weight\n",
            "features.6.3.block.1.1.bias\n",
            "features.6.3.block.1.1.running_mean\n",
            "features.6.3.block.1.1.running_var\n",
            "features.6.3.block.1.1.num_batches_tracked\n",
            "features.6.3.block.2.fc1.weight\n",
            "features.6.3.block.2.fc1.bias\n",
            "features.6.3.block.2.fc2.weight\n",
            "features.6.3.block.2.fc2.bias\n",
            "features.6.3.block.3.0.weight\n",
            "features.6.3.block.3.1.weight\n",
            "features.6.3.block.3.1.bias\n",
            "features.6.3.block.3.1.running_mean\n",
            "features.6.3.block.3.1.running_var\n",
            "features.6.3.block.3.1.num_batches_tracked\n",
            "features.7.0.block.0.0.weight\n",
            "features.7.0.block.0.1.weight\n",
            "features.7.0.block.0.1.bias\n",
            "features.7.0.block.0.1.running_mean\n",
            "features.7.0.block.0.1.running_var\n",
            "features.7.0.block.0.1.num_batches_tracked\n",
            "features.7.0.block.1.0.weight\n",
            "features.7.0.block.1.1.weight\n",
            "features.7.0.block.1.1.bias\n",
            "features.7.0.block.1.1.running_mean\n",
            "features.7.0.block.1.1.running_var\n",
            "features.7.0.block.1.1.num_batches_tracked\n",
            "features.7.0.block.2.fc1.weight\n",
            "features.7.0.block.2.fc1.bias\n",
            "features.7.0.block.2.fc2.weight\n",
            "features.7.0.block.2.fc2.bias\n",
            "features.7.0.block.3.0.weight\n",
            "features.7.0.block.3.1.weight\n",
            "features.7.0.block.3.1.bias\n",
            "features.7.0.block.3.1.running_mean\n",
            "features.7.0.block.3.1.running_var\n",
            "features.7.0.block.3.1.num_batches_tracked\n",
            "features.8.0.weight\n",
            "features.8.1.weight\n",
            "features.8.1.bias\n",
            "features.8.1.running_mean\n",
            "features.8.1.running_var\n",
            "features.8.1.num_batches_tracked\n",
            "classifier.1.weight\n",
            "classifier.1.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "xH703Qa2vLbi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path('models')\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = 'model.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
        "torch.save(obj=state, f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "ZmRO8XXUvLVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92888ac-1b50-463b-80b4-4b67abe5c2b6"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Model"
      ],
      "metadata": {
        "id": "ugOrS2cx5LMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = efficientnet_b0()"
      ],
      "metadata": {
        "id": "jeD0BQh2f4fJ"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Shape of original model's weight is ([1000, 1280]), need it to be ([6, 1280])\n",
        "- Shape of original model's bias is ([1000]), need it to be ([6])"
      ],
      "metadata": {
        "id": "n-B-tAPApsKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlLntJ7n3Xq9",
        "outputId": "aa56fb67-da01-4067-ba14-e1ba30dd4743"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.2, inplace=True)\n",
              "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.classifier = nn.Linear(loaded_model.classifier[-1].in_features, NUM_CLASSES)\n",
        "loaded_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqw9XIdb3nW6",
        "outputId": "9827843e-4e0d-4b14-c3b6-3c59018169bf"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1280, out_features=6, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH), strict=False)\n",
        "loaded_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7anxlhf-fXG6",
        "outputId": "09ccedf0-a640-4931-d444-5ee234b4ca94"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1280, out_features=6, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert XML Images to CSV\n",
        "\n",
        "# def xml_to_csv(path):\n",
        "#     xml_list = []\n",
        "#     for xml_file in glob.glob(path + '/*.xml'):\n",
        "#         tree = ET.parse(xml_file)\n",
        "#         root = tree.getroot()\n",
        "#         for child in root.findall('object'):\n",
        "#             # print(child)\n",
        "#             # Following the structure of the XML images at /images\n",
        "#             value = (root.find('filename').text,\n",
        "#                      int(root.find('size')[0].text),\n",
        "#                      int(root.find('size')[0].text),\n",
        "#                      child[0].text,\n",
        "#                      int(child[4][0].text),\n",
        "#                      int(child[4][1].text),\n",
        "#                      int(child[4][2].text),\n",
        "#                      int(child[4][3].text)\n",
        "#                      )\n",
        "#             #print(f'\\nValues: \\n{value}')\n",
        "#             xml_list.append(value)\n",
        "\n",
        "#     column_name = ['filename', 'width', 'height',\n",
        "#                    'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "#     xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "#     return xml_df"
      ],
      "metadata": {
        "id": "enfm0q1seeAB"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}