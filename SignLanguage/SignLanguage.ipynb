{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChAI-o2McZbi"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights, vgg11, VGG11_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Label Map"
      ],
      "metadata": {
        "id": "W2lULp5Ce7iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    {'name': 'hello', 'id': 1},\n",
        "    {'name': 'yes', 'id': 2},\n",
        "    {'name': 'no', 'id': 3},\n",
        "    {'name': 'thanks', 'id': 4},\n",
        "    {'name': 'i love you', 'id': 5},\n",
        "]"
      ],
      "metadata": {
        "id": "ZgV6IlabeeFy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/annotations/\""
      ],
      "metadata": {
        "id": "5JUFI7svfUBo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/annotations/label_map.pbtxt', 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write(f'\\tname:\\'{label[\"name\"]}\\'\\n')\n",
        "        f.write(f'\\tid:{label[\"id\"]}\\n')\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "Y_8SEVEZeeC3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to Colab to get Images"
      ],
      "metadata": {
        "id": "ozpzfqhSgImy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eZyJ4a0gLgQ",
        "outputId": "614a9a87-79ef-4b24-ebd3-bb17ec3f4c77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/IA/SignLanguageImages.zip\" -d \"/content/images\""
      ],
      "metadata": {
        "id": "ak-ltHXgiWqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8534b344-57cd-40bb-b25d-3bbec34e55db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/IA/SignLanguageImages.zip\n",
            "   creating: /content/images/test/\n",
            "  inflating: /content/images/test/2024-01-22-122318_1.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122318_1.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122318_2.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122318_2.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122318_3.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122318_3.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122318_4.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122318_4.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122536_1.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122536_1.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122536_2.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122536_2.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122536_3.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122536_3.xml  \n",
            "  inflating: /content/images/test/2024-01-22-122536_4.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-122536_4.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123007_1.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123007_1.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123007_2.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123007_2.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123007_3.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123007_3.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123007_4.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123007_4.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123500_1.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123500_1.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123500_2.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123500_2.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123500_3.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123500_3.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123500_4.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123500_4.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123659_1.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123659_1.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123659_2.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123659_2.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123659_3.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123659_3.xml  \n",
            "  inflating: /content/images/test/2024-01-22-123659_4.jpg  \n",
            "  inflating: /content/images/test/2024-01-22-123659_4.xml  \n",
            "  inflating: /content/images/test/hello.1636369e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/hello.1636369e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/hello.17697030-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/hello.17697030-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/iloveyou.643300ca-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/iloveyou.643300ca-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/iloveyou.65662e54-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/iloveyou.65662e54-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/no.54990236-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/no.54990236-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/no.58320d48-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/no.58320d48-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/thanks.223197d6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/thanks.223197d6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/thanks.29631fe8-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/thanks.29631fe8-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/yes.356557d4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/yes.356557d4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/test/yes.36989634-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/test/yes.36989634-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "   creating: /content/images/train/\n",
            "  inflating: /content/images/train/2024-01-22-160639_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160639_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160639_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160639_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160639_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160639_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160639_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160639_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160849_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160849_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160849_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160849_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160849_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160849_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160849_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160849_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160933_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160933_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160933_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160933_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160933_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160933_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-160933_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-160933_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161011_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161011_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161011_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161011_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161011_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161011_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161011_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161011_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161102_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161102_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161102_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161102_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161102_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161102_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-161102_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-161102_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162027_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162027_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162027_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162027_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162027_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162027_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162027_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162027_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162110_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162110_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162110_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162110_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162110_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162110_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162110_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162110_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162151_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162151_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162151_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162151_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162151_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162151_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162151_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162151_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162230_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162230_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162230_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162230_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162230_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162230_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162230_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162230_4.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162314_1.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162314_1.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162314_2.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162314_2.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162314_3.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162314_3.xml  \n",
            "  inflating: /content/images/train/2024-01-22-162314_4.jpg  \n",
            "  inflating: /content/images/train/2024-01-22-162314_4.xml  \n",
            "  inflating: /content/images/train/hello.07b8a200-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.07b8a200-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.08ff8ab6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.08ff8ab6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0a32d26c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0a32d26c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0b6614a0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0b6614a0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0c9c8872-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0c9c8872-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0dd0807c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0dd0807c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.0f03c15c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.0f03c15c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.10371a4c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.10371a4c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.116a0c08-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.116a0c08-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.129d16ba-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.129d16ba-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.13d00236-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.13d00236-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.1502fabe-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.1502fabe-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/hello.189cc68c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/hello.189cc68c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.5e308968-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.5e308968-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.5f6684cc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.5f6684cc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6099b01c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6099b01c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.61cccb4a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.61cccb4a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.62ffc0b2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.62ffc0b2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6699e1e4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6699e1e4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.67cd878c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.67cd878c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6900b17e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6900b17e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6a33b37a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6a33b37a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6b6713d6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6b6713d6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6c9daee0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6c9daee0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6dd0a9a2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6dd0a9a2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/iloveyou.6f03c6b0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/iloveyou.6f03c6b0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4895e2ce-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4895e2ce-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.49c94ac8-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.49c94ac8-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4afc7ff0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4afc7ff0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4c2f8264-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4c2f8264-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4d628c9e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4d628c9e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4e956988-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4e956988-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.4fc86d5a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.4fc86d5a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.50fb6e84-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.50fb6e84-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.522efc4e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.522efc4e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.5365fe1e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.5365fe1e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.55cbcd50-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.55cbcd50-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.56fec54c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.56fec54c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/no.5968d066-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/no.5968d066-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1d61b312-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1d61b312-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1e9781bc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1e9781bc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.1fcaa99c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.1fcaa99c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.20fde9f0-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.20fde9f0-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.23646c32-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.23646c32-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.24970d26-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.24970d26-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.25ca3bdc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.25ca3bdc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.26fcf5e4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.26fcf5e4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.282ff4ca-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.282ff4ca-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2a96002e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2a96002e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2bc8f866-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2bc8f866-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2cfc1e34-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2cfc1e34-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/thanks.2e300c3e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/thanks.2e300c3e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.32fbfab6-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.32fbfab6-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.34320a9c-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.34320a9c-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.37cbab04-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.37cbab04-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.38feb796-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.38feb796-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3a31b014-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3a31b014-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3b649e92-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3b649e92-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3c979b34-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3c979b34-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3dca9d08-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3dca9d08-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.3efd905e-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.3efd905e-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.40309aa2-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.40309aa2-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.4163b12a-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.4163b12a-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.4296bbb4-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.4296bbb4-b0f2-11ee-bc1a-5b91ca12c195.xml  \n",
            "  inflating: /content/images/train/yes.43c9debc-b0f2-11ee-bc1a-5b91ca12c195.jpg  \n",
            "  inflating: /content/images/train/yes.43c9debc-b0f2-11ee-bc1a-5b91ca12c195.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SignDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None,\n",
        "                 device='cpu'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "\n",
        "        self.image_label_pairs = []\n",
        "        split_dir = os.path.join(root_dir, split)\n",
        "\n",
        "        for filename in os.listdir(split_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img_path = os.path.join(split_dir, filename)\n",
        "                label_filename = os.path.splitext(filename)[0] + '.xml'\n",
        "                label_path = os.path.join(split_dir, label_filename)\n",
        "                if os.path.exists(label_path):\n",
        "                    self.image_label_pairs.append((img_path, label_path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_label_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label_path = self.image_label_pairs[idx]\n",
        "\n",
        "        def normalize_bbox(bbox, image_size):\n",
        "            l = []\n",
        "            for item in bbox:\n",
        "                l.append((item / image_size) * 2 - 1)\n",
        "            return l\n",
        "\n",
        "        # Load Image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Convert to numpy array\n",
        "        # img = np.array(img)\n",
        "\n",
        "        # # Normalize image\n",
        "        # img = img / 255.0\n",
        "\n",
        "        # Load XML file and extract label information\n",
        "        tree = ET.parse(label_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Extract label information\n",
        "        object_elem = root.find('object')\n",
        "        class_name = object_elem.find('name').text\n",
        "        bbox_elem = object_elem.find('bndbox')\n",
        "        xmin = int(bbox_elem.find('xmin').text)\n",
        "        ymin = int(bbox_elem.find('ymin').text)\n",
        "        xmax = int(bbox_elem.find('xmax').text)\n",
        "        ymax = int(bbox_elem.find('ymax').text)\n",
        "\n",
        "        label = class_name\n",
        "        bbox = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "        # Original image dimensions\n",
        "        original_width, original_height = img.size\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Resized image dimensions\n",
        "        resized_width = img.shape[1]\n",
        "        resized_height = img.shape[2]\n",
        "\n",
        "        width_ratio = resized_width / original_width\n",
        "        height_ratio = resized_height / original_height\n",
        "\n",
        "        # Adjusting bbox coordinates to the new image shape\n",
        "        adjusted_bbox_xmin = xmin * width_ratio\n",
        "        adjusted_bbox_ymin = ymin * height_ratio\n",
        "        adjusted_bbox_xmax = xmax * width_ratio\n",
        "        adjusted_bbox_ymax = ymax * height_ratio\n",
        "\n",
        "        bbox = [adjusted_bbox_xmin, adjusted_bbox_ymin,\n",
        "                adjusted_bbox_xmax, adjusted_bbox_ymax]\n",
        "\n",
        "        # Normalize bounding box coordinates\n",
        "        image_size = img.shape[1]  # Get image size for normalization\n",
        "        # print(image_size, bbox)\n",
        "        bbox = normalize_bbox(bbox, image_size)\n",
        "        # print(bbox)\n",
        "\n",
        "        return img, label, bbox"
      ],
      "metadata": {
        "id": "ZcXuVEUsdJEO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "nPyryh28eU5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=(0, 30)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.3, p=1.0),\n",
        "    transforms.ColorJitter(brightness=.5, hue=.3),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "eq8CpTGCdo6V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "cedreQCMKvvj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Dataset"
      ],
      "metadata": {
        "id": "__EUi9pseZul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SignDataset(root_dir='/content/images', split='train',\n",
        "                            transform=transform, device=device)\n",
        "test_dataset = SignDataset(root_dir='/content/images', split='test',\n",
        "                           transform=transform, device=device)"
      ],
      "metadata": {
        "id": "fVkzErFHd1RW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA_nmpUnMnZ6",
        "outputId": "89440828-18e8-41cd-b42e-363e61e62eea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
              " 'no',\n",
              " [-0.928125, -0.55, -0.38750000000000007, 0.23750000000000004])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyLxiMdvnpND",
        "outputId": "8e9b6794-3ee0-4547-da84-b967c4c39fa2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-yASdkgoW02",
        "outputId": "7d5f8dfe-1b32-46ac-ea9a-03af842b629f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Pretrained Model"
      ],
      "metadata": {
        "id": "rxNrHi8Sv5rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "def get_state_dict(self, *args, **kwargs):\n",
        "    kwargs.pop(\"check_hash\")\n",
        "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "class CustomEfficientNetB0(nn.Module):\n",
        "    def __init__(self, num_classes, num_coordinates=4):\n",
        "        super(CustomEfficientNetB0, self).__init__()\n",
        "        efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "        self.model = efficientnet_b0(weights=\"DEFAULT\")\n",
        "        in_features = self.model.classifier[-1].in_features\n",
        "\n",
        "        # Altering last layer's output size\n",
        "        self.model.classifier[1] = nn.Linear(1280, 1280, bias=True)\n",
        "\n",
        "        # Freeze all layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.regressor_head = nn.Sequential(\n",
        "            nn.Linear(in_features, num_coordinates),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier_head = nn.Sequential(\n",
        "            nn.Linear(in_features, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.model(x)\n",
        "        # print(f'x: {x.shape}')\n",
        "        # print(f'y: {y.shape}')\n",
        "\n",
        "        class_logits = self.classifier_head(y)\n",
        "        bbox_regression = self.regressor_head(y)\n",
        "        return class_logits, bbox_regression"
      ],
      "metadata": {
        "id": "MU4fm8QdJsyU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomEfficientNetB0(num_classes=6, num_coordinates=4)"
      ],
      "metadata": {
        "id": "QYwIDvQMMSW_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1yRrjidyZn5",
        "outputId": "4abb8372-501e-4cce-d239-520c24586883"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomEfficientNetB0(\n",
              "  (model): EfficientNet(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (2): Conv2dNormActivation(\n",
              "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (8): Conv2dNormActivation(\n",
              "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (classifier): Sequential(\n",
              "      (0): Dropout(p=0.2, inplace=True)\n",
              "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (regressor_head): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (classifier_head): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=6, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier_head)\n",
        "print(model.regressor_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBXXIU231qlQ",
        "outputId": "e95e1a3a-b242-4fac-ce75-07c0228724da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1280, out_features=6, bias=True)\n",
            "  (1): Sigmoid()\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=1280, out_features=4, bias=True)\n",
            "  (1): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "HA8Stuqqxiwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_classification = nn.CrossEntropyLoss()\n",
        "loss_fn_regression = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Ba6ZVYnBvLsM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "-yCWak0QzoTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "cC1z0Si8vLpQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_index_mapping = {label['name']: label['id'] for label in labels}\n",
        "class_index_mapping"
      ],
      "metadata": {
        "id": "txiAe1Mt2WZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de68219-703b-4ddd-eb8a-2865c7da602a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hello': 1, 'yes': 2, 'no': 3, 'thanks': 4, 'i love you': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][1], train_dataset[0][2]"
      ],
      "metadata": {
        "id": "aIju5rp8A_WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fc2706-65f1-4f4f-e13f-5cf78fe29553"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('thanks',\n",
              " [-0.4625, -0.11249999999999993, 0.7437499999999999, 0.8291666666666668])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_torch = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device_torch)\n",
        "next(model.parameters()).is_cuda"
      ],
      "metadata": {
        "id": "CH9e6HzPNaaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ed74de-fe1c-473d-89bb-96d41f213602"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(train_dataset)):\n",
        "    sample = train_dataset[idx]\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7YeosVgNhwA",
        "outputId": "751d48db-5359-42da-c5e4-2c6ccfe4f1f6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'yes', [-0.34687500000000004, -0.9958333333333333, 0.4375, -0.3375])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    running_classification_loss = 0.0\n",
        "    running_regression_loss = 0.0\n",
        "\n",
        "    for idx in range(len(train_dataset)):\n",
        "        sample = train_dataset[idx]\n",
        "        # Getting the image (0), the label (1) and the bounding box (2)\n",
        "        x, y, bbox = sample[0], sample[1], sample[2]\n",
        "        x = x.to(device)\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        # Forward pass\n",
        "        class_logits, bbox_regression = model(x)\n",
        "        class_logits = class_logits.to(device)\n",
        "        bbox_regression = bbox_regression.to(device)\n",
        "\n",
        "        # Classification loss\n",
        "        label = torch.tensor(class_index_mapping[y], device=device)\n",
        "        classification_loss = loss_fn_classification(class_logits, label.unsqueeze(0))\n",
        "\n",
        "        # Regression loss\n",
        "        bbox_gt = torch.tensor(bbox, dtype=torch.float32, device=device)\n",
        "        regression_loss = loss_fn_regression(bbox_regression, bbox_gt.unsqueeze(0))\n",
        "\n",
        "        # Giving an increased weight to regression\n",
        "        cls_weight = 0.5\n",
        "        reg_weight = 1.0\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = cls_weight * classification_loss + reg_weight * regression_loss\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_classification_loss += classification_loss.item()\n",
        "        running_regression_loss += regression_loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{EPOCHS}], '\n",
        "          f'Classification Loss: {running_classification_loss / len(train_dataset)}, '\n",
        "          f'Regression Loss: {running_regression_loss / len(train_dataset)}')"
      ],
      "metadata": {
        "id": "T6xgELwOvLla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ae114d-d0a7-45ff-f236-85d141ec92e5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Classification Loss: 1.7720766635168166, Regression Loss: 0.36473258407343\n",
            "Epoch [2/10], Classification Loss: 1.7400719165802, Regression Loss: 0.3536955484322139\n",
            "Epoch [3/10], Classification Loss: 1.7223409925188338, Regression Loss: 0.34906217462959743\n",
            "Epoch [4/10], Classification Loss: 1.7080015579859416, Regression Loss: 0.34872622340917586\n",
            "Epoch [5/10], Classification Loss: 1.697907040232704, Regression Loss: 0.34674246765318373\n",
            "Epoch [6/10], Classification Loss: 1.6925312030883062, Regression Loss: 0.34334436576990857\n",
            "Epoch [7/10], Classification Loss: 1.6902865909394764, Regression Loss: 0.34291196217139563\n",
            "Epoch [8/10], Classification Loss: 1.6861977849687848, Regression Loss: 0.3467420072782607\n",
            "Epoch [9/10], Classification Loss: 1.6848551954541888, Regression Loss: 0.3449827002627509\n",
            "Epoch [10/10], Classification Loss: 1.68471113159543, Regression Loss: 0.3475455240834327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model"
      ],
      "metadata": {
        "id": "rYHWYz0wCCP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_classification_loss = 0.0\n",
        "        running_regression_loss = 0.0\n",
        "\n",
        "        for idx in range(len(test_dataset)):\n",
        "            sample = test_dataset[idx]\n",
        "            # Getting the image (0), the label (1) and the bounding box (2)\n",
        "            x, y, bbox = sample[0], sample[1], sample[2]\n",
        "            x = x.to(device)\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "            # Forward pass\n",
        "            class_logits, bbox_regression = model(x)\n",
        "            class_logits = class_logits.to(device)\n",
        "            bbox_regression = bbox_regression.to(device)\n",
        "\n",
        "            # Classification loss\n",
        "            label = torch.tensor(class_index_mapping[y], device=device)\n",
        "            classification_loss = loss_fn_classification(class_logits, label.unsqueeze(0))\n",
        "\n",
        "            # Regression loss\n",
        "            bbox_gt = torch.tensor(bbox, dtype=torch.float32, device=device)\n",
        "            regression_loss = loss_fn_regression(bbox_regression, bbox_gt.unsqueeze(0))\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = classification_loss + regression_loss\n",
        "\n",
        "            running_classification_loss += classification_loss.item()\n",
        "            running_regression_loss += regression_loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], '\n",
        "            f'Classification Loss: {running_classification_loss / len(test_dataset)}, '\n",
        "            f'Regression Loss: {running_regression_loss / len(test_dataset)}')"
      ],
      "metadata": {
        "id": "lGnqCKjGvLiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098c7223-e69b-4ace-b7f5-ff918644b7f6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Classification Loss: 1.6965954303741455, Regression Loss: 0.41345249662796657\n",
            "Epoch [2/10], Classification Loss: 1.7003987669944762, Regression Loss: 0.43323517392079036\n",
            "Epoch [3/10], Classification Loss: 1.6993077556292215, Regression Loss: 0.41030975927909213\n",
            "Epoch [4/10], Classification Loss: 1.7031237403551738, Regression Loss: 0.4191895763079325\n",
            "Epoch [5/10], Classification Loss: 1.6932000557581584, Regression Loss: 0.42276677836974463\n",
            "Epoch [6/10], Classification Loss: 1.690177365144094, Regression Loss: 0.4331310580174128\n",
            "Epoch [7/10], Classification Loss: 1.7012104630470275, Regression Loss: 0.43160213232040406\n",
            "Epoch [8/10], Classification Loss: 1.7063844442367553, Regression Loss: 0.4360866367816925\n",
            "Epoch [9/10], Classification Loss: 1.6943241953849792, Regression Loss: 0.42082010507583617\n",
            "Epoch [10/10], Classification Loss: 1.7114178895950318, Regression Loss: 0.4406295508146286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the Weights of the Model"
      ],
      "metadata": {
        "id": "WZisOlyLVlWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = model.state_dict()\n",
        "# state['classifier.1.weight'] = state['classifier.weight']\n",
        "# del state['classifier.weight']\n",
        "# state['classifier.1.bias'] = state['classifier.bias']\n",
        "# del state['classifier.bias']"
      ],
      "metadata": {
        "id": "kVtISBYcnH0P"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in state.items():\n",
        "    print(key)"
      ],
      "metadata": {
        "id": "QXw_SEk3iSg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded6c566-fe28-4542-dc5d-c6e2f6cbd8c8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.features.0.0.weight\n",
            "model.features.0.1.weight\n",
            "model.features.0.1.bias\n",
            "model.features.0.1.running_mean\n",
            "model.features.0.1.running_var\n",
            "model.features.0.1.num_batches_tracked\n",
            "model.features.1.0.block.0.0.weight\n",
            "model.features.1.0.block.0.1.weight\n",
            "model.features.1.0.block.0.1.bias\n",
            "model.features.1.0.block.0.1.running_mean\n",
            "model.features.1.0.block.0.1.running_var\n",
            "model.features.1.0.block.0.1.num_batches_tracked\n",
            "model.features.1.0.block.1.fc1.weight\n",
            "model.features.1.0.block.1.fc1.bias\n",
            "model.features.1.0.block.1.fc2.weight\n",
            "model.features.1.0.block.1.fc2.bias\n",
            "model.features.1.0.block.2.0.weight\n",
            "model.features.1.0.block.2.1.weight\n",
            "model.features.1.0.block.2.1.bias\n",
            "model.features.1.0.block.2.1.running_mean\n",
            "model.features.1.0.block.2.1.running_var\n",
            "model.features.1.0.block.2.1.num_batches_tracked\n",
            "model.features.2.0.block.0.0.weight\n",
            "model.features.2.0.block.0.1.weight\n",
            "model.features.2.0.block.0.1.bias\n",
            "model.features.2.0.block.0.1.running_mean\n",
            "model.features.2.0.block.0.1.running_var\n",
            "model.features.2.0.block.0.1.num_batches_tracked\n",
            "model.features.2.0.block.1.0.weight\n",
            "model.features.2.0.block.1.1.weight\n",
            "model.features.2.0.block.1.1.bias\n",
            "model.features.2.0.block.1.1.running_mean\n",
            "model.features.2.0.block.1.1.running_var\n",
            "model.features.2.0.block.1.1.num_batches_tracked\n",
            "model.features.2.0.block.2.fc1.weight\n",
            "model.features.2.0.block.2.fc1.bias\n",
            "model.features.2.0.block.2.fc2.weight\n",
            "model.features.2.0.block.2.fc2.bias\n",
            "model.features.2.0.block.3.0.weight\n",
            "model.features.2.0.block.3.1.weight\n",
            "model.features.2.0.block.3.1.bias\n",
            "model.features.2.0.block.3.1.running_mean\n",
            "model.features.2.0.block.3.1.running_var\n",
            "model.features.2.0.block.3.1.num_batches_tracked\n",
            "model.features.2.1.block.0.0.weight\n",
            "model.features.2.1.block.0.1.weight\n",
            "model.features.2.1.block.0.1.bias\n",
            "model.features.2.1.block.0.1.running_mean\n",
            "model.features.2.1.block.0.1.running_var\n",
            "model.features.2.1.block.0.1.num_batches_tracked\n",
            "model.features.2.1.block.1.0.weight\n",
            "model.features.2.1.block.1.1.weight\n",
            "model.features.2.1.block.1.1.bias\n",
            "model.features.2.1.block.1.1.running_mean\n",
            "model.features.2.1.block.1.1.running_var\n",
            "model.features.2.1.block.1.1.num_batches_tracked\n",
            "model.features.2.1.block.2.fc1.weight\n",
            "model.features.2.1.block.2.fc1.bias\n",
            "model.features.2.1.block.2.fc2.weight\n",
            "model.features.2.1.block.2.fc2.bias\n",
            "model.features.2.1.block.3.0.weight\n",
            "model.features.2.1.block.3.1.weight\n",
            "model.features.2.1.block.3.1.bias\n",
            "model.features.2.1.block.3.1.running_mean\n",
            "model.features.2.1.block.3.1.running_var\n",
            "model.features.2.1.block.3.1.num_batches_tracked\n",
            "model.features.3.0.block.0.0.weight\n",
            "model.features.3.0.block.0.1.weight\n",
            "model.features.3.0.block.0.1.bias\n",
            "model.features.3.0.block.0.1.running_mean\n",
            "model.features.3.0.block.0.1.running_var\n",
            "model.features.3.0.block.0.1.num_batches_tracked\n",
            "model.features.3.0.block.1.0.weight\n",
            "model.features.3.0.block.1.1.weight\n",
            "model.features.3.0.block.1.1.bias\n",
            "model.features.3.0.block.1.1.running_mean\n",
            "model.features.3.0.block.1.1.running_var\n",
            "model.features.3.0.block.1.1.num_batches_tracked\n",
            "model.features.3.0.block.2.fc1.weight\n",
            "model.features.3.0.block.2.fc1.bias\n",
            "model.features.3.0.block.2.fc2.weight\n",
            "model.features.3.0.block.2.fc2.bias\n",
            "model.features.3.0.block.3.0.weight\n",
            "model.features.3.0.block.3.1.weight\n",
            "model.features.3.0.block.3.1.bias\n",
            "model.features.3.0.block.3.1.running_mean\n",
            "model.features.3.0.block.3.1.running_var\n",
            "model.features.3.0.block.3.1.num_batches_tracked\n",
            "model.features.3.1.block.0.0.weight\n",
            "model.features.3.1.block.0.1.weight\n",
            "model.features.3.1.block.0.1.bias\n",
            "model.features.3.1.block.0.1.running_mean\n",
            "model.features.3.1.block.0.1.running_var\n",
            "model.features.3.1.block.0.1.num_batches_tracked\n",
            "model.features.3.1.block.1.0.weight\n",
            "model.features.3.1.block.1.1.weight\n",
            "model.features.3.1.block.1.1.bias\n",
            "model.features.3.1.block.1.1.running_mean\n",
            "model.features.3.1.block.1.1.running_var\n",
            "model.features.3.1.block.1.1.num_batches_tracked\n",
            "model.features.3.1.block.2.fc1.weight\n",
            "model.features.3.1.block.2.fc1.bias\n",
            "model.features.3.1.block.2.fc2.weight\n",
            "model.features.3.1.block.2.fc2.bias\n",
            "model.features.3.1.block.3.0.weight\n",
            "model.features.3.1.block.3.1.weight\n",
            "model.features.3.1.block.3.1.bias\n",
            "model.features.3.1.block.3.1.running_mean\n",
            "model.features.3.1.block.3.1.running_var\n",
            "model.features.3.1.block.3.1.num_batches_tracked\n",
            "model.features.4.0.block.0.0.weight\n",
            "model.features.4.0.block.0.1.weight\n",
            "model.features.4.0.block.0.1.bias\n",
            "model.features.4.0.block.0.1.running_mean\n",
            "model.features.4.0.block.0.1.running_var\n",
            "model.features.4.0.block.0.1.num_batches_tracked\n",
            "model.features.4.0.block.1.0.weight\n",
            "model.features.4.0.block.1.1.weight\n",
            "model.features.4.0.block.1.1.bias\n",
            "model.features.4.0.block.1.1.running_mean\n",
            "model.features.4.0.block.1.1.running_var\n",
            "model.features.4.0.block.1.1.num_batches_tracked\n",
            "model.features.4.0.block.2.fc1.weight\n",
            "model.features.4.0.block.2.fc1.bias\n",
            "model.features.4.0.block.2.fc2.weight\n",
            "model.features.4.0.block.2.fc2.bias\n",
            "model.features.4.0.block.3.0.weight\n",
            "model.features.4.0.block.3.1.weight\n",
            "model.features.4.0.block.3.1.bias\n",
            "model.features.4.0.block.3.1.running_mean\n",
            "model.features.4.0.block.3.1.running_var\n",
            "model.features.4.0.block.3.1.num_batches_tracked\n",
            "model.features.4.1.block.0.0.weight\n",
            "model.features.4.1.block.0.1.weight\n",
            "model.features.4.1.block.0.1.bias\n",
            "model.features.4.1.block.0.1.running_mean\n",
            "model.features.4.1.block.0.1.running_var\n",
            "model.features.4.1.block.0.1.num_batches_tracked\n",
            "model.features.4.1.block.1.0.weight\n",
            "model.features.4.1.block.1.1.weight\n",
            "model.features.4.1.block.1.1.bias\n",
            "model.features.4.1.block.1.1.running_mean\n",
            "model.features.4.1.block.1.1.running_var\n",
            "model.features.4.1.block.1.1.num_batches_tracked\n",
            "model.features.4.1.block.2.fc1.weight\n",
            "model.features.4.1.block.2.fc1.bias\n",
            "model.features.4.1.block.2.fc2.weight\n",
            "model.features.4.1.block.2.fc2.bias\n",
            "model.features.4.1.block.3.0.weight\n",
            "model.features.4.1.block.3.1.weight\n",
            "model.features.4.1.block.3.1.bias\n",
            "model.features.4.1.block.3.1.running_mean\n",
            "model.features.4.1.block.3.1.running_var\n",
            "model.features.4.1.block.3.1.num_batches_tracked\n",
            "model.features.4.2.block.0.0.weight\n",
            "model.features.4.2.block.0.1.weight\n",
            "model.features.4.2.block.0.1.bias\n",
            "model.features.4.2.block.0.1.running_mean\n",
            "model.features.4.2.block.0.1.running_var\n",
            "model.features.4.2.block.0.1.num_batches_tracked\n",
            "model.features.4.2.block.1.0.weight\n",
            "model.features.4.2.block.1.1.weight\n",
            "model.features.4.2.block.1.1.bias\n",
            "model.features.4.2.block.1.1.running_mean\n",
            "model.features.4.2.block.1.1.running_var\n",
            "model.features.4.2.block.1.1.num_batches_tracked\n",
            "model.features.4.2.block.2.fc1.weight\n",
            "model.features.4.2.block.2.fc1.bias\n",
            "model.features.4.2.block.2.fc2.weight\n",
            "model.features.4.2.block.2.fc2.bias\n",
            "model.features.4.2.block.3.0.weight\n",
            "model.features.4.2.block.3.1.weight\n",
            "model.features.4.2.block.3.1.bias\n",
            "model.features.4.2.block.3.1.running_mean\n",
            "model.features.4.2.block.3.1.running_var\n",
            "model.features.4.2.block.3.1.num_batches_tracked\n",
            "model.features.5.0.block.0.0.weight\n",
            "model.features.5.0.block.0.1.weight\n",
            "model.features.5.0.block.0.1.bias\n",
            "model.features.5.0.block.0.1.running_mean\n",
            "model.features.5.0.block.0.1.running_var\n",
            "model.features.5.0.block.0.1.num_batches_tracked\n",
            "model.features.5.0.block.1.0.weight\n",
            "model.features.5.0.block.1.1.weight\n",
            "model.features.5.0.block.1.1.bias\n",
            "model.features.5.0.block.1.1.running_mean\n",
            "model.features.5.0.block.1.1.running_var\n",
            "model.features.5.0.block.1.1.num_batches_tracked\n",
            "model.features.5.0.block.2.fc1.weight\n",
            "model.features.5.0.block.2.fc1.bias\n",
            "model.features.5.0.block.2.fc2.weight\n",
            "model.features.5.0.block.2.fc2.bias\n",
            "model.features.5.0.block.3.0.weight\n",
            "model.features.5.0.block.3.1.weight\n",
            "model.features.5.0.block.3.1.bias\n",
            "model.features.5.0.block.3.1.running_mean\n",
            "model.features.5.0.block.3.1.running_var\n",
            "model.features.5.0.block.3.1.num_batches_tracked\n",
            "model.features.5.1.block.0.0.weight\n",
            "model.features.5.1.block.0.1.weight\n",
            "model.features.5.1.block.0.1.bias\n",
            "model.features.5.1.block.0.1.running_mean\n",
            "model.features.5.1.block.0.1.running_var\n",
            "model.features.5.1.block.0.1.num_batches_tracked\n",
            "model.features.5.1.block.1.0.weight\n",
            "model.features.5.1.block.1.1.weight\n",
            "model.features.5.1.block.1.1.bias\n",
            "model.features.5.1.block.1.1.running_mean\n",
            "model.features.5.1.block.1.1.running_var\n",
            "model.features.5.1.block.1.1.num_batches_tracked\n",
            "model.features.5.1.block.2.fc1.weight\n",
            "model.features.5.1.block.2.fc1.bias\n",
            "model.features.5.1.block.2.fc2.weight\n",
            "model.features.5.1.block.2.fc2.bias\n",
            "model.features.5.1.block.3.0.weight\n",
            "model.features.5.1.block.3.1.weight\n",
            "model.features.5.1.block.3.1.bias\n",
            "model.features.5.1.block.3.1.running_mean\n",
            "model.features.5.1.block.3.1.running_var\n",
            "model.features.5.1.block.3.1.num_batches_tracked\n",
            "model.features.5.2.block.0.0.weight\n",
            "model.features.5.2.block.0.1.weight\n",
            "model.features.5.2.block.0.1.bias\n",
            "model.features.5.2.block.0.1.running_mean\n",
            "model.features.5.2.block.0.1.running_var\n",
            "model.features.5.2.block.0.1.num_batches_tracked\n",
            "model.features.5.2.block.1.0.weight\n",
            "model.features.5.2.block.1.1.weight\n",
            "model.features.5.2.block.1.1.bias\n",
            "model.features.5.2.block.1.1.running_mean\n",
            "model.features.5.2.block.1.1.running_var\n",
            "model.features.5.2.block.1.1.num_batches_tracked\n",
            "model.features.5.2.block.2.fc1.weight\n",
            "model.features.5.2.block.2.fc1.bias\n",
            "model.features.5.2.block.2.fc2.weight\n",
            "model.features.5.2.block.2.fc2.bias\n",
            "model.features.5.2.block.3.0.weight\n",
            "model.features.5.2.block.3.1.weight\n",
            "model.features.5.2.block.3.1.bias\n",
            "model.features.5.2.block.3.1.running_mean\n",
            "model.features.5.2.block.3.1.running_var\n",
            "model.features.5.2.block.3.1.num_batches_tracked\n",
            "model.features.6.0.block.0.0.weight\n",
            "model.features.6.0.block.0.1.weight\n",
            "model.features.6.0.block.0.1.bias\n",
            "model.features.6.0.block.0.1.running_mean\n",
            "model.features.6.0.block.0.1.running_var\n",
            "model.features.6.0.block.0.1.num_batches_tracked\n",
            "model.features.6.0.block.1.0.weight\n",
            "model.features.6.0.block.1.1.weight\n",
            "model.features.6.0.block.1.1.bias\n",
            "model.features.6.0.block.1.1.running_mean\n",
            "model.features.6.0.block.1.1.running_var\n",
            "model.features.6.0.block.1.1.num_batches_tracked\n",
            "model.features.6.0.block.2.fc1.weight\n",
            "model.features.6.0.block.2.fc1.bias\n",
            "model.features.6.0.block.2.fc2.weight\n",
            "model.features.6.0.block.2.fc2.bias\n",
            "model.features.6.0.block.3.0.weight\n",
            "model.features.6.0.block.3.1.weight\n",
            "model.features.6.0.block.3.1.bias\n",
            "model.features.6.0.block.3.1.running_mean\n",
            "model.features.6.0.block.3.1.running_var\n",
            "model.features.6.0.block.3.1.num_batches_tracked\n",
            "model.features.6.1.block.0.0.weight\n",
            "model.features.6.1.block.0.1.weight\n",
            "model.features.6.1.block.0.1.bias\n",
            "model.features.6.1.block.0.1.running_mean\n",
            "model.features.6.1.block.0.1.running_var\n",
            "model.features.6.1.block.0.1.num_batches_tracked\n",
            "model.features.6.1.block.1.0.weight\n",
            "model.features.6.1.block.1.1.weight\n",
            "model.features.6.1.block.1.1.bias\n",
            "model.features.6.1.block.1.1.running_mean\n",
            "model.features.6.1.block.1.1.running_var\n",
            "model.features.6.1.block.1.1.num_batches_tracked\n",
            "model.features.6.1.block.2.fc1.weight\n",
            "model.features.6.1.block.2.fc1.bias\n",
            "model.features.6.1.block.2.fc2.weight\n",
            "model.features.6.1.block.2.fc2.bias\n",
            "model.features.6.1.block.3.0.weight\n",
            "model.features.6.1.block.3.1.weight\n",
            "model.features.6.1.block.3.1.bias\n",
            "model.features.6.1.block.3.1.running_mean\n",
            "model.features.6.1.block.3.1.running_var\n",
            "model.features.6.1.block.3.1.num_batches_tracked\n",
            "model.features.6.2.block.0.0.weight\n",
            "model.features.6.2.block.0.1.weight\n",
            "model.features.6.2.block.0.1.bias\n",
            "model.features.6.2.block.0.1.running_mean\n",
            "model.features.6.2.block.0.1.running_var\n",
            "model.features.6.2.block.0.1.num_batches_tracked\n",
            "model.features.6.2.block.1.0.weight\n",
            "model.features.6.2.block.1.1.weight\n",
            "model.features.6.2.block.1.1.bias\n",
            "model.features.6.2.block.1.1.running_mean\n",
            "model.features.6.2.block.1.1.running_var\n",
            "model.features.6.2.block.1.1.num_batches_tracked\n",
            "model.features.6.2.block.2.fc1.weight\n",
            "model.features.6.2.block.2.fc1.bias\n",
            "model.features.6.2.block.2.fc2.weight\n",
            "model.features.6.2.block.2.fc2.bias\n",
            "model.features.6.2.block.3.0.weight\n",
            "model.features.6.2.block.3.1.weight\n",
            "model.features.6.2.block.3.1.bias\n",
            "model.features.6.2.block.3.1.running_mean\n",
            "model.features.6.2.block.3.1.running_var\n",
            "model.features.6.2.block.3.1.num_batches_tracked\n",
            "model.features.6.3.block.0.0.weight\n",
            "model.features.6.3.block.0.1.weight\n",
            "model.features.6.3.block.0.1.bias\n",
            "model.features.6.3.block.0.1.running_mean\n",
            "model.features.6.3.block.0.1.running_var\n",
            "model.features.6.3.block.0.1.num_batches_tracked\n",
            "model.features.6.3.block.1.0.weight\n",
            "model.features.6.3.block.1.1.weight\n",
            "model.features.6.3.block.1.1.bias\n",
            "model.features.6.3.block.1.1.running_mean\n",
            "model.features.6.3.block.1.1.running_var\n",
            "model.features.6.3.block.1.1.num_batches_tracked\n",
            "model.features.6.3.block.2.fc1.weight\n",
            "model.features.6.3.block.2.fc1.bias\n",
            "model.features.6.3.block.2.fc2.weight\n",
            "model.features.6.3.block.2.fc2.bias\n",
            "model.features.6.3.block.3.0.weight\n",
            "model.features.6.3.block.3.1.weight\n",
            "model.features.6.3.block.3.1.bias\n",
            "model.features.6.3.block.3.1.running_mean\n",
            "model.features.6.3.block.3.1.running_var\n",
            "model.features.6.3.block.3.1.num_batches_tracked\n",
            "model.features.7.0.block.0.0.weight\n",
            "model.features.7.0.block.0.1.weight\n",
            "model.features.7.0.block.0.1.bias\n",
            "model.features.7.0.block.0.1.running_mean\n",
            "model.features.7.0.block.0.1.running_var\n",
            "model.features.7.0.block.0.1.num_batches_tracked\n",
            "model.features.7.0.block.1.0.weight\n",
            "model.features.7.0.block.1.1.weight\n",
            "model.features.7.0.block.1.1.bias\n",
            "model.features.7.0.block.1.1.running_mean\n",
            "model.features.7.0.block.1.1.running_var\n",
            "model.features.7.0.block.1.1.num_batches_tracked\n",
            "model.features.7.0.block.2.fc1.weight\n",
            "model.features.7.0.block.2.fc1.bias\n",
            "model.features.7.0.block.2.fc2.weight\n",
            "model.features.7.0.block.2.fc2.bias\n",
            "model.features.7.0.block.3.0.weight\n",
            "model.features.7.0.block.3.1.weight\n",
            "model.features.7.0.block.3.1.bias\n",
            "model.features.7.0.block.3.1.running_mean\n",
            "model.features.7.0.block.3.1.running_var\n",
            "model.features.7.0.block.3.1.num_batches_tracked\n",
            "model.features.8.0.weight\n",
            "model.features.8.1.weight\n",
            "model.features.8.1.bias\n",
            "model.features.8.1.running_mean\n",
            "model.features.8.1.running_var\n",
            "model.features.8.1.num_batches_tracked\n",
            "model.classifier.1.weight\n",
            "model.classifier.1.bias\n",
            "regressor_head.0.weight\n",
            "regressor_head.0.bias\n",
            "classifier_head.0.weight\n",
            "classifier_head.0.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "xH703Qa2vLbi"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = Path('models')\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = 'model.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
        "torch.save(obj=state, f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "ZmRO8XXUvLVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1774209-9254-49b0-a40d-19488e0cc58e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Model"
      ],
      "metadata": {
        "id": "ugOrS2cx5LMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 6"
      ],
      "metadata": {
        "id": "jYao83RLAk_q"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = CustomEfficientNetB0(num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "jeD0BQh2f4fJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.classifier_head, loaded_model.regressor_head"
      ],
      "metadata": {
        "id": "VlLntJ7n3Xq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4a9357-b001-4a60-dffc-8e1ebe933d52"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Sequential(\n",
              "   (0): Linear(in_features=1280, out_features=6, bias=True)\n",
              "   (1): Sigmoid()\n",
              " ),\n",
              " Sequential(\n",
              "   (0): Linear(in_features=1280, out_features=4, bias=True)\n",
              "   (1): ReLU()\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH), strict=False)\n",
        "loaded_model"
      ],
      "metadata": {
        "id": "7anxlhf-fXG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1b17d7-b921-40e6-ecf6-e6559af8e8f3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomEfficientNetB0(\n",
              "  (model): EfficientNet(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (2): Conv2dNormActivation(\n",
              "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "        )\n",
              "        (1): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "        )\n",
              "        (2): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "        )\n",
              "        (3): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (7): Sequential(\n",
              "        (0): MBConv(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2dNormActivation(\n",
              "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): SqueezeExcitation(\n",
              "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (activation): SiLU(inplace=True)\n",
              "              (scale_activation): Sigmoid()\n",
              "            )\n",
              "            (3): Conv2dNormActivation(\n",
              "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "        )\n",
              "      )\n",
              "      (8): Conv2dNormActivation(\n",
              "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): SiLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "    (classifier): Sequential(\n",
              "      (0): Dropout(p=0.2, inplace=True)\n",
              "      (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (regressor_head): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (classifier_head): Sequential(\n",
              "    (0): Linear(in_features=1280, out_features=6, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def predict_on_webcam(model, labels, transform):\n",
        "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # You may need to preprocess the frame, depending on the model's input requirements\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_tensor = transform(frame).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            output = model(frame_tensor)\n",
        "\n",
        "        _, predicted_class = torch.max(output, 1)\n",
        "        predicted_label = labels[predicted_class.item()]\n",
        "\n",
        "        # Draw bounding box on the frame\n",
        "        bbox = [100, 100, 300, 300]  # Replace this with your model's prediction\n",
        "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, predicted_label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow('Prediction', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "1F3KnhRp8_G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert XML Images to CSV\n",
        "\n",
        "# def xml_to_csv(path):\n",
        "#     xml_list = []\n",
        "#     for xml_file in glob.glob(path + '/*.xml'):\n",
        "#         tree = ET.parse(xml_file)\n",
        "#         root = tree.getroot()\n",
        "#         for child in root.findall('object'):\n",
        "#             # print(child)\n",
        "#             # Following the structure of the XML images at /images\n",
        "#             value = (root.find('filename').text,\n",
        "#                      int(root.find('size')[0].text),\n",
        "#                      int(root.find('size')[0].text),\n",
        "#                      child[0].text,\n",
        "#                      int(child[4][0].text),\n",
        "#                      int(child[4][1].text),\n",
        "#                      int(child[4][2].text),\n",
        "#                      int(child[4][3].text)\n",
        "#                      )\n",
        "#             #print(f'\\nValues: \\n{value}')\n",
        "#             xml_list.append(value)\n",
        "\n",
        "#     column_name = ['filename', 'width', 'height',\n",
        "#                    'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "#     xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "#     return xml_df"
      ],
      "metadata": {
        "id": "enfm0q1seeAB"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}